# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n1NmwS-K9M6Y-TM3T3VtPQlhHBD3rbHK
"""

# Load the Drive helper and mount
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np

def example_load():
    """
    Demonstrates an example of loading the data for the project. The
    features vectors for the samples are stored in IR_MS_FUNCTIONAL_X.npy
    while the correspong labels are stored in IR_MS_FUNCTIONAL_y.npy. Labels
    and feature vectors will share the same index. For example the label for
        IR_MS_FUNCTIONAL_X[1412]
    will be
        IR_MS_FUNCTIONAL_y[1412]

    The feature vectors have the form:

        [ ... ir data ... , ... ms data ... ]

    where each entry is a floating point value. The labels will take the form

        [ FUNC_GRP_1 , FUNC_GRP_2 , ... , FUNC_GRP_N ]

    where FUNC_GRP_i is a binary value indicating whether or not that 
    functional group is present.
    """

    # NOTE: These paths may need to change, depending on where you've
    # saved IR_MS_FUNCTIONAL_X.npy and IR_MS_FUNCTIONAL_y.npy. If you've
    # saved both npy files in the same directory as this example.py file,
    # just remove 'data' as a parameter to os.path.join and just use
    # os.path.join('IR_MS_FUNCTIONAL_X.npy').
    x_data_path = os.path.join('/content', 'drive', 'My Drive', 'STAT4402 Project', 'IR_MS_FUNCTIONAL_X.npy')
    y_data_path = os.path.join('/content', 'drive', 'My Drive', 'STAT4402 Project', 'IR_MS_FUNCTIONAL_y.npy')

    IR_MS_FUNCTIONAL_X = np.load(x_data_path)
    IR_MS_FUNCTIONAL_y = np.load(y_data_path)

    print(IR_MS_FUNCTIONAL_X.shape)
    print(IR_MS_FUNCTIONAL_y.shape)

    print()

    print(IR_MS_FUNCTIONAL_X[0])
    print()

    print(IR_MS_FUNCTIONAL_y[0])
    print()
    
    return IR_MS_FUNCTIONAL_X, IR_MS_FUNCTIONAL_y

IR_MS_FUNCTIONAL_X, IR_MS_FUNCTIONAL_y = example_load()

import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

# hot2int = [np.where(r == np.unique(IR_MS_FUNCTIONAL_y, axis=0)) for r in IR_MS_FUNCTIONAL_y[1]]
#[np.where(r==1)[0][0] for r in IR_MS_FUNCTIONAL_y]
# print(hot2int)

from pprint import pprint
unique_vecs = np.unique(IR_MS_FUNCTIONAL_y, axis=0)

mapping = { tuple(vector) : num for vector, num in zip(iter(unique_vecs), range(len(unique_vecs))) }

mapped_value = [ mapping[tuple(y_val)] for y_val in IR_MS_FUNCTIONAL_y ]
pprint(mapped_value)

steps = [('scaler', StandardScaler()), ('SVM', SVC(kernel='poly'))]
pipe = Pipeline(steps,verbose=True) # define Pipeline object
pipe.fit(IR_MS_FUNCTIONAL_X, mapped_value)

pipe.score(IR_MS_FUNCTIONAL_X, mapped_value)



from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(IR_MS_FUNCTIONAL_X, mapped_value, test_size=0.3, random_state=42)

steps = [('scaler', StandardScaler()), ('PCA', PCA(n_components = 100)), ('RForest', RandomForestClassifier(max_depth=50, n_jobs =-1, criterion= 'entropy', verbose = 1 ))]
pipe = Pipeline(steps,verbose=True) # define Pipeline object
pipe.fit(X_train, y_train)

pipe.score(X_test, y_test)